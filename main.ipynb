{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_collect():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(\"/Users/gal.bachar/git_wa/HIT/Data-science-Weather/chromedriver/chromedriver\", options=chrome_options)\n",
    "    df = pd.DataFrame([], columns=[\"year\", \"month\", \"day\", \"temp\", \"humidity\", \"windspeed\", \"precipitation\"])\n",
    "    df_row_count=1\n",
    "\n",
    "    # switch temp from fahrenheit to celsius\n",
    "    driver.get(f\"https://www.wunderground.com/history/monthly/us/ny/new-york-city/KLGA/date/1970-1\")\n",
    "    settings = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"wuSettings\")))\n",
    "    settings.click()\n",
    "    time.sleep(2)\n",
    "    celsius = WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.XPATH,\n",
    "                                                                              '//*[@id=\"wuSettings-quick\"]/div/a[2]')))\n",
    "    celsius.click()\n",
    "\n",
    "    for year in range(1970,2023):\n",
    "        for month in range(1,13):\n",
    "            try:\n",
    "                driver.get(f\"https://www.wunderground.com/history/monthly/us/ny/new-york-city/KLGA/date/{year}-{month}\")\n",
    "                print(f'{month}-{year}')\n",
    "            except Exception as e:\n",
    "                print(f'{e} - unable to get: {month}.{year}')\n",
    "            try:\n",
    "                table_id= WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"days\")))\n",
    "                data = table_id.find_elements(By.TAG_NAME, \"table\") # get all of the rows in the table\n",
    "                num_of_days = len(data[1].find_elements(By.TAG_NAME, \"tr\"))\n",
    "\n",
    "                for i in range(1,num_of_days):\n",
    "                    day = int(data[0].find_elements(By.TAG_NAME, \"tr\")[i].text)\n",
    "                    temp = float(data[1].find_elements(By.TAG_NAME, \"tr\")[i].text.split(' ')[1])\n",
    "                    humidity = float(data[3].find_elements(By.TAG_NAME, \"tr\")[i].text.split(' ')[1])\n",
    "                    windspeed = float(data[4].find_elements(By.TAG_NAME, \"tr\")[i].text.split(' ')[1])\n",
    "                    precipitation = float(data[6].find_elements(By.TAG_NAME, \"tr\")[i].text)\n",
    "                    day_data = [year,month,day,temp,humidity,windspeed,precipitation]\n",
    "                    df.loc[df_row_count] = day_data\n",
    "                    df_row_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"cloud not get {year}-{month} data: {e}\")\n",
    "\n",
    "    driver.quit()\n",
    "    df.to_csv('~/Documents/nyc_weather.csv',index=False) #for debugging\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data_df, good_weather_values):\n",
    "    norm_df = data_df.copy()\n",
    "\n",
    "    for i in norm_df.columns:\n",
    "        if i not in ['year', 'month', 'day']:\n",
    "            good_min = good_weather_values[i][0]\n",
    "            good_max = good_weather_values[i][1]\n",
    "            diff_min = good_weather_values[i][0] - norm_df[i].min()\n",
    "            diff_max = norm_df[i].max() - good_weather_values[i][1]\n",
    "            norm_df.loc[(norm_df[i] < good_min), i] = 1 - ((good_min - norm_df[i]) / diff_min)\n",
    "            norm_df.loc[(norm_df[i] > good_max), i] = 1 - ((norm_df[i] - good_max) / diff_max)\n",
    "            norm_df.loc[(norm_df[i] <= good_max) & (norm_df[i] >= good_min), i] = 1\n",
    "    norm_df.insert(7, \"pleasant day\", 0)\n",
    "    norm_df.loc[(norm_df[\"temp\"] > 0),\"pleasant day\"] = (norm_df[\"temp\"] + norm_df[\"humidity\"] + norm_df[\"windspeed\"] + norm_df[\"precipitation\"]) / 4\n",
    "    norm_df.loc[(norm_df[\"temp\"] > 0) & (norm_df[\"precipitation\"].isna()), \"pleasant day\"] = (norm_df[\"temp\"] + norm_df[\"humidity\"] + norm_df[\"windspeed\"]) / 3\n",
    "\n",
    "    # norm_df.to_csv('~/Documents/nyc_weather_norm.csv', index=False)  # for debugging\n",
    "\n",
    "    return norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_data(data):\n",
    "    data.loc[data[\"year\"] <= 2014, \"precipitation\"] = np.NaN\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_good_days_per_month(data):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    months=['Jan', 'Feb','Mar','Apr','May','jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    res = {}\n",
    "    for i in range(0,12):\n",
    "        res[months[i]] = len(data.loc[(data['month'] == (i+1)) & (data['pleasant day'] >= 0.9)])\n",
    "    ser = pd.Series(res)\n",
    "    # print(ser)\n",
    "    ser.plot(kind='pie', ax=axes, title = \"All time good days per month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_good_days_trends(data):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(20, 5))\n",
    "    months=['Jan', 'Feb','Mar','Apr','May','jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    res = {}\n",
    "    for j in range(1970,2022):\n",
    "        for i in range(0,12):\n",
    "            #print(data.loc[((data['month'] == (i+1)) & (data['year'] == j)),'pleasant day'].mean())\n",
    "            res[f\"{i + 1}-{j}\"] = round(data.loc[((data['month'] == (i+1)) & (data['year'] == j)),'pleasant day'].mean(),2)\n",
    "    ser = pd.Series(res)\n",
    "    # print(ser)\n",
    "    ser.plot(kind='line', ax=axes, title = \"Num of good days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_good_days(data):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(20, 5))\n",
    "    ser = pd.Series(data[\"pleasant day\"])\n",
    "    # print(ser)\n",
    "    ser.plot(kind='line', ax=axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highly_correlated_cols(data):\n",
    "    col_correlated = set()\n",
    "    tuple_array = []\n",
    "    correlations = []\n",
    "    for i in range (len(data.corr().columns)):\n",
    "        for j in range(i):\n",
    "            if(data.corr().iloc[j, i] >= 0.5) and (data.corr().columns[i] not in col_correlated):\n",
    "                correlations.append(data.corr().iloc[i, j])\n",
    "                tuple_array.append([j, i])\n",
    "    return correlations, tuple_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_correlated_scatters(data):\n",
    "    fig, axes = plt.subplots(1, len(correlations), figsize = (20, 5))\n",
    "    axe_i = 0\n",
    "    index = np.argsort(correlations)\n",
    "    columns = list(data.columns)\n",
    "    for n_correlation in index:\n",
    "        col_lt, col_rt = tuple_arr[n_correlation]\n",
    "        col_left_title, col_right_title = columns[col_lt], columns[col_rt]\n",
    "        title = \"corr('%s', '%s') = %4.2f\" % (col_left_title, col_right_title, correlations[n_correlation])\n",
    "        data.plot(x = col_left_title, y = col_right_title, kind = \"scatter\",\n",
    "                ax = axes[axe_i], title = title, xlabel = col_left_title, ylabel = col_right_title)\n",
    "        axe_i = axe_i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_corrupt_rows(df, num_max_missing_cols):\n",
    "    cp = df.dropna(thresh=len(df.columns)-num_max_missing_cols).copy()\n",
    "    return cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutliers(df):\n",
    "    all_outliers = {}\n",
    "    fig, axes = plt.subplots(1, len(df.columns) - 3, figsize = (20, 5))\n",
    "    axe_i = 0\n",
    "    for col in df.columns:\n",
    "        z_score_value=3\n",
    "        if col not in [\"year\", \"month\", \"day\"]:    \n",
    "            #plt.hist(df[col],bins=50, ax=axes[axe_i])\n",
    "            ax = df[col].plot(bins=50, ax=axes[axe_i], kind=\"hist\")\n",
    "            axe_i = axe_i + 1\n",
    "            ax.set(xlabel=col)\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            # looking for outliers using distances of standard deviation from the mean.\n",
    "            z_score = (df[col] - df[col].mean()) / df[col].std()\n",
    "            if col in [\"humidity\"]:\n",
    "                z_score_value=2.5\n",
    "            outliers = abs(z_score) > z_score_value # after some tests if we will search for lower distance we will lost important information.\n",
    "            print (f\"Number of outliers for {col} - {sum(outliers)}\")\n",
    "            all_outliers[col] = outliers\n",
    "    return all_outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showOutliers(all_outliers):\n",
    "    fig, axes = plt.subplots(1, len(df.columns) - 3, figsize = (20, 5))\n",
    "    axe_i = 0\n",
    "    for col in all_outliers:\n",
    "        ser = pd.Series(df.loc[all_outliers[col],col])\n",
    "        ser.plot(kind=\"hist\", ax=axes[axe_i], title = f\"Outliers for {col}\")\n",
    "        axe_i = axe_i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],

   "source": [
    "# nice weather:\n",
    "# temp 18-25\n",
    "# humidity 30-50%\n",
    "# windspeed 0-7\n",
    "# precipitation 0 - 0.5\n",
    "good_weather_values = {'temp': [20,23], 'humidity':[30,40],'windspeed':[4,7], 'precipitation':[0,1]}\n",
    "# df = data_collect()\n",
    "df = pd.read_csv('~/Documents/nyc_weather.csv') # for debugging\n",
    "# fixed_data = remove_missing_data(df)\n",
    "# norm_df = normalize_data(fixed_data, good_weather_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All data\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataframe describe\")\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outliers = getOutliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show outliers\n",
    "showOutliers(all_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_df = normalize_data(df, good_weather_values)\n",
    "print(\"All data - normalized\")\n",
    "norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "num_of_good_days_per_month(norm_df)\n",
    "num_of_good_days_trends(norm_df)\n",
    "#num_of_good_days(norm_df)\n",
    "correlations, tuple_arr = get_highly_correlated_cols(norm_df)\n",
    "high_correlated_scatters(norm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c53fc6fe09d1fc45c22adc6d00f56873dfa8a784c30473ddd47ecc0cffa49afa"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
